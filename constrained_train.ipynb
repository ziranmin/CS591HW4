{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2002\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SpanishStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function for Word Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_shape(word):\n",
    "    word = re.sub('[A-Z]|[Ã€-Ãš]', 'X', word)\n",
    "    word = re.sub('[a-z]|[Ã -Ãº]', 'x', word)\n",
    "    word = re.sub('[0-9]', 'd', word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_word_shape(word):\n",
    "    shape = word_shape(word)\n",
    "    \n",
    "    short_shape = ''\n",
    "    prev_shape = ''\n",
    "    is_punctuation = False\n",
    "\n",
    "    for i in range(len(shape)):\n",
    "        if shape[i] == 'X':\n",
    "            curr_shape = 'X'\n",
    "        elif shape[i] == 'x':\n",
    "            curr_shape = 'x'\n",
    "        elif shape[i] == 'd':\n",
    "            curr_shape = 'd'\n",
    "        else:\n",
    "            is_punctuation = True\n",
    "            curr_shape = shape[i]\n",
    "        if is_punctuation or curr_shape != prev_shape:\n",
    "            short_shape += curr_shape\n",
    "            \n",
    "        is_punctuation = False\n",
    "        prev_shape = curr_shape\n",
    "        \n",
    "    return short_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfeats(word, pos, o):\n",
    "    \"\"\" This takes the word in question and\n",
    "    the offset with respect to the instance\n",
    "    word \"\"\"\n",
    "    \n",
    "    has_hyphen = 0\n",
    "    if \"-\" in word:\n",
    "        has_hyphen = 1\n",
    "        \n",
    "    has_apostrophe = 0\n",
    "    if \"'\" in word:\n",
    "        has_apostrophe = 1\n",
    "        \n",
    "    stemmer = SpanishStemmer() \n",
    "    \n",
    "    o = str(o)\n",
    "    features = [\n",
    "        (o + 'word', word),\n",
    "        (o + 'pos', pos),\n",
    "        (o + 'prefix1', word[:1]), \n",
    "        (o + 'prefix2', word[:2]),\n",
    "        (o + 'prefix3', word[:3]),\n",
    "        (o + 'prefix4', word[:4]),\n",
    "        (o + 'suffix1', word[-1:]), \n",
    "        (o + 'suffix2', word[-2:]), \n",
    "        (o + 'suffix3', word[-3:]), \n",
    "        (o + 'suffix4', word[-4:]), \n",
    "        (o + 'is_upper', word.isupper()),\n",
    "        (o + 'is_title', word.istitle()),\n",
    "        (o + 'is_digit', word.isdigit()),\n",
    "        (o + 'has_hypen', has_hyphen),\n",
    "        (o + 'has_apostrophe', has_apostrophe),\n",
    "        (o + 'spanich_stem', stemmer.stem(word)),\n",
    "        (o + 'word_shape', word_shape(word)),\n",
    "        (o + 'short_word_shape', short_word_shape(word))\n",
    "    ]\n",
    "    #print(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    \"\"\" The function generates all features\n",
    "    for the word at position i in the\n",
    "    sentence.\"\"\"\n",
    "    features = []\n",
    "    # the window around the token\n",
    "    #for o in [-1,0,1]:\n",
    "    for o in [-2,-1,0,1,2]:\n",
    "        if i+o >= 0 and i+o < len(sent):\n",
    "            word = sent[i+o][0]\n",
    "            pos = sent[i+o][1]\n",
    "            featlist = getfeats(word, pos, o)\n",
    "            if o==0:\n",
    "                if i == 0:\n",
    "                    featlist.append((\"beginning\", True))\n",
    "                elif i == len(sent)-1:\n",
    "                    featlist.append((\"ending\", True))\n",
    "            \n",
    "            features.extend(featlist)\n",
    "    \n",
    "    return dict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = list(conll2002.iob_sents('esp.train'))\n",
    "dev_sents = list(conll2002.iob_sents('esp.testa'))\n",
    "test_sents = list(conll2002.iob_sents('esp.testb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Features to Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = []\n",
    "train_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in train_sents:\n",
    "    for i in range(len(sent)):\n",
    "        feats = word2features(sent,i)\n",
    "        train_feats.append(feats)\n",
    "        train_labels.append(sent[i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "#model = Perceptron(verbose=1)\n",
    "model.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Features to Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in dev_sents:\n",
    "    for i in range(len(sent)):\n",
    "        feats = word2features(sent,i)\n",
    "        test_feats.append(feats)\n",
    "        test_labels.append(sent[i][-1])\n",
    "\n",
    "X_test = vectorizer.transform(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Output for Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.txt\", \"w\") as out:\n",
    "    for sent in dev_sents: \n",
    "        for i in range(len(sent)):\n",
    "            word = sent[i][0]\n",
    "            gold = sent[i][-1]\n",
    "            pred = y_pred[j]\n",
    "            j += 1\n",
    "            out.write(\"{}\\t{}\\t{}\\n\".format(word,gold,pred))\n",
    "    out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
