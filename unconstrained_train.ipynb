{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2002\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from nltk.stem.snowball import SpanishStemmer\n",
    "import re\n",
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function for Word Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_shape(word):\n",
    "    word = re.sub('[A-Z]|[À-Ú]', 'X', word)\n",
    "    word = re.sub('[a-z]|[à-ú]', 'x', word)\n",
    "    word = re.sub('[0-9]', 'd', word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_word_shape(word):\n",
    "    shape = word_shape(word)\n",
    "    \n",
    "    short_shape = ''\n",
    "    prev_shape = ''\n",
    "    is_punctuation = False\n",
    "\n",
    "    for i in range(len(shape)):\n",
    "        if shape[i] == 'X':\n",
    "            curr_shape = 'X'\n",
    "        elif shape[i] == 'x':\n",
    "            curr_shape = 'x'\n",
    "        elif shape[i] == 'd':\n",
    "            curr_shape = 'd'\n",
    "        else:\n",
    "            is_punctuation = True\n",
    "            curr_shape = shape[i]\n",
    "        if is_punctuation or curr_shape != prev_shape:\n",
    "            short_shape += curr_shape\n",
    "            \n",
    "        is_punctuation = False\n",
    "        prev_shape = curr_shape\n",
    "        \n",
    "    return short_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfeats(word, pos, o):\n",
    "    \"\"\" This takes the word in question and\n",
    "    the offset with respect to the instance\n",
    "    word \"\"\"\n",
    "    \n",
    "    has_hyphen = 0\n",
    "    if \"-\" in word:\n",
    "        has_hyphen = 1\n",
    "        \n",
    "    has_apostrophe = 0\n",
    "    if \"'\" in word:\n",
    "        has_apostrophe = 1\n",
    "        \n",
    "    stemmer = SpanishStemmer() \n",
    "    \n",
    "    o = str(o)\n",
    "    features = [\n",
    "        (o + 'word', word),\n",
    "        (o + 'pos', pos),\n",
    "        (o + 'prefix1', word[:1]), \n",
    "        (o + 'prefix2', word[:2]),\n",
    "        (o + 'prefix3', word[:3]),\n",
    "        (o + 'prefix4', word[:4]),\n",
    "        (o + 'suffix1', word[-1:]), \n",
    "        (o + 'suffix2', word[-2:]), \n",
    "        (o + 'suffix3', word[-3:]), \n",
    "        (o + 'suffix4', word[-4:]), \n",
    "        (o + 'is_upper', word.isupper()),\n",
    "        (o + 'is_title', word.istitle()),\n",
    "        (o + 'is_digit', word.isdigit()),\n",
    "        (o + 'has_hypen', has_hyphen),\n",
    "        (o + 'has_apostrophe', has_apostrophe),\n",
    "        (o + 'spanich_stem', stemmer.stem(word)),\n",
    "        (o + 'word_shape', word_shape(word)),\n",
    "        (o + 'short_word_shape', short_word_shape(word))\n",
    "    ]\n",
    "    #print(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    \"\"\" The function generates all features\n",
    "    for the word at position i in the\n",
    "    sentence.\"\"\"\n",
    "    features = []\n",
    "    # the window around the token\n",
    "    #for o in [-1,0,1]:\n",
    "    for o in [-2,-1,0,1,2]:\n",
    "        if i+o >= 0 and i+o < len(sent):\n",
    "            word = sent[i+o][0]\n",
    "            pos = sent[i+o][1]\n",
    "            featlist = getfeats(word, pos, o)\n",
    "            if o==0:\n",
    "                if i == 0:\n",
    "                    featlist.append((\"beginning\", True))\n",
    "                elif i == len(sent)-1:\n",
    "                    featlist.append((\"ending\", True))\n",
    "            \n",
    "            features.extend(featlist)\n",
    "    \n",
    "    return dict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = list(conll2002.iob_sents('esp.train'))\n",
    "dev_sents = list(conll2002.iob_sents('esp.testa'))\n",
    "test_sents = list(conll2002.iob_sents('esp.testb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Features to Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = []\n",
    "train_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in train_sents:\n",
    "    local_feats = []\n",
    "    loca_labels = []\n",
    "    for i in range(len(sent)):\n",
    "        feats = word2features(sent,i)\n",
    "        local_feats.append(feats)\n",
    "        loca_labels.append(sent[i][-1])\n",
    "    train_feats += [local_feats]\n",
    "    train_labels += [loca_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Different Parameters in CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xseq, yseq in zip(train_feats, train_labels):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c1 = 0\n",
    "c1 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2 = 0\n",
    "c2 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 100\n",
    "#max_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': c1,   \n",
    "    'c2': c2,  \n",
    "    'max_iterations': max_iterations,  \n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_algo = 'lbfgs'\n",
    "#train_algo = 'l2sgd'\n",
    "#train_algo = 'ap'\n",
    "#train_algo = 'pa'\n",
    "#train_algo = 'arow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.select(train_algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x1aa412d8d0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in dev_sents:\n",
    "    local_feats = []\n",
    "    loca_labels = []\n",
    "    for i in range(len(sent)):\n",
    "        feats = word2features(sent,i)\n",
    "        local_feats.append(feats)\n",
    "        loca_labels.append(sent[i][-1])\n",
    "        \n",
    "    test_feats += [local_feats]\n",
    "    test_labels += [loca_labels]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in test_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.txt\", \"w\") as out:\n",
    "    for i in range(len(dev_sents)): \n",
    "        sent = dev_sents[i]\n",
    "        for j in range(len(sent)):\n",
    "            word = sent[j][0]\n",
    "            gold = sent[j][-1]\n",
    "            pred = y_pred[i][j]\n",
    "            out.write(\"{}\\t{}\\t{}\\n\".format(word,gold,pred))\n",
    "    out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to Find best C1 and C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-8c94293d0c31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         trainer.set_params({\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    for j in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        trainer = pycrfsuite.Trainer(verbose=False)\n",
    "        \n",
    "        for xseq, yseq in zip(train_feats, train_labels):\n",
    "            trainer.append(xseq, yseq)\n",
    "            \n",
    "        trainer.set_params({\n",
    "            'c1': i,   \n",
    "            'c2': j,  \n",
    "            'max_iterations': 100,  \n",
    "            'feature.possible_transitions': True\n",
    "            })\n",
    "        trainer.select('lbfgs')\n",
    "        trainer.train('conll2002-esp.crfsuite')\n",
    "        tagger = pycrfsuite.Tagger()\n",
    "        tagger.open('conll2002-esp.crfsuite')\n",
    "        y_pred = [tagger.tag(xseq) for xseq in test_feats]\n",
    "        \n",
    "        filename = \"results_\" + str(i) + \"_\" + str(j) + \".txt\"\n",
    "        \n",
    "        with open(filename, \"w\") as out:\n",
    "            for i in range(len(dev_sents)): \n",
    "                sent = dev_sents[i]\n",
    "                for j in range(len(sent)):\n",
    "                    word = sent[j][0]\n",
    "                    gold = sent[j][-1]\n",
    "                    pred = y_pred[i][j]\n",
    "                    out.write(\"{}\\t{}\\t{}\\n\".format(word,gold,pred))\n",
    "            out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
