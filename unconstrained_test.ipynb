{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2002\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from nltk.stem.snowball import SpanishStemmer\n",
    "import re\n",
    "import pycrfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Function for Word Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_shape(word):\n",
    "    word = re.sub('[A-Z]|[À-Ú]', 'X', word)\n",
    "    word = re.sub('[a-z]|[à-ú]', 'x', word)\n",
    "    word = re.sub('[0-9]', 'd', word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_word_shape(word):\n",
    "    shape = word_shape(word)\n",
    "    \n",
    "    short_shape = ''\n",
    "    prev_shape = ''\n",
    "    is_punctuation = False\n",
    "\n",
    "    for i in range(len(shape)):\n",
    "        if shape[i] == 'X':\n",
    "            curr_shape = 'X'\n",
    "        elif shape[i] == 'x':\n",
    "            curr_shape = 'x'\n",
    "        elif shape[i] == 'd':\n",
    "            curr_shape = 'd'\n",
    "        else:\n",
    "            is_punctuation = True\n",
    "            curr_shape = shape[i]\n",
    "        if is_punctuation or curr_shape != prev_shape:\n",
    "            short_shape += curr_shape\n",
    "            \n",
    "        is_punctuation = False\n",
    "        prev_shape = curr_shape\n",
    "        \n",
    "    return short_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfeats(word, pos, o):\n",
    "    \"\"\" This takes the word in question and\n",
    "    the offset with respect to the instance\n",
    "    word \"\"\"\n",
    "    \n",
    "    has_hyphen = 0\n",
    "    if \"-\" in word:\n",
    "        has_hyphen = 1\n",
    "        \n",
    "    has_apostrophe = 0\n",
    "    if \"'\" in word:\n",
    "        has_apostrophe = 1\n",
    "        \n",
    "    stemmer = SpanishStemmer() \n",
    "    \n",
    "    o = str(o)\n",
    "    features = [\n",
    "        (o + 'word', word),\n",
    "        (o + 'pos', pos),\n",
    "        (o + 'prefix1', word[:1]), \n",
    "        (o + 'prefix2', word[:2]),\n",
    "        (o + 'prefix3', word[:3]),\n",
    "        (o + 'prefix4', word[:4]),\n",
    "        (o + 'suffix1', word[-1:]), \n",
    "        (o + 'suffix2', word[-2:]), \n",
    "        (o + 'suffix3', word[-3:]), \n",
    "        (o + 'suffix4', word[-4:]), \n",
    "        (o + 'is_upper', word.isupper()),\n",
    "        (o + 'is_title', word.istitle()),\n",
    "        (o + 'is_digit', word.isdigit()),\n",
    "        (o + 'has_hypen', has_hyphen),\n",
    "        (o + 'has_apostrophe', has_apostrophe),\n",
    "        (o + 'spanich_stem', stemmer.stem(word)),\n",
    "        (o + 'word_shape', word_shape(word)),\n",
    "        (o + 'short_word_shape', short_word_shape(word))\n",
    "    ]\n",
    "    #print(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    \"\"\" The function generates all features\n",
    "    for the word at position i in the\n",
    "    sentence.\"\"\"\n",
    "    features = []\n",
    "    # the window around the token\n",
    "    #for o in [-1,0,1]:\n",
    "    for o in [-2,-1,0,1,2]:\n",
    "        if i+o >= 0 and i+o < len(sent):\n",
    "            word = sent[i+o][0]\n",
    "            pos = sent[i+o][1]\n",
    "            featlist = getfeats(word, pos, o)\n",
    "            if o==0:\n",
    "                if i == 0:\n",
    "                    featlist.append((\"beginning\", True))\n",
    "                elif i == len(sent)-1:\n",
    "                    featlist.append((\"ending\", True))\n",
    "            \n",
    "            features.extend(featlist)\n",
    "    \n",
    "    return dict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data, Combine Training and Validation Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = list(conll2002.iob_sents('esp.train'))\n",
    "dev_sents = list(conll2002.iob_sents('esp.testa'))\n",
    "\n",
    "train_sents = train_sents + dev_sents\n",
    "\n",
    "test_sents = list(conll2002.iob_sents('esp.testb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = []\n",
    "train_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in train_sents:\n",
    "    local_feats = []\n",
    "    loca_labels = []\n",
    "    for i in range(len(sent)):\n",
    "        feats = word2features(sent,i)\n",
    "        local_feats.append(feats)\n",
    "        loca_labels.append(sent[i][-1])\n",
    "    train_feats += [local_feats]\n",
    "    train_labels += [loca_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unconstrained CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xseq, yseq in zip(train_feats, train_labels):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 0.1,   \n",
    "    'c2': 0.1,  \n",
    "    'max_iterations': 100,  \n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.select('l2sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x1a1398e630>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('conll2002-esp.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in test_sents:\n",
    "    local_feats = []\n",
    "    loca_labels = []\n",
    "    for i in range(len(sent)):\n",
    "        feats = word2features(sent,i)\n",
    "        local_feats.append(feats)\n",
    "        loca_labels.append(sent[i][-1])\n",
    "        \n",
    "    test_feats += [local_feats]\n",
    "    test_labels += [loca_labels]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in test_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"unconstrained_results.txt\", \"w\") as out:\n",
    "    for i in range(len(test_sents)): \n",
    "        sent = test_sents[i]\n",
    "        for j in range(len(sent)):\n",
    "            word = sent[j][0]\n",
    "            gold = sent[j][-1]\n",
    "            pred = y_pred[i][j]\n",
    "            out.write(\"{}\\t{}\\t{}\\n\".format(word,gold,pred))\n",
    "    out.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
